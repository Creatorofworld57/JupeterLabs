{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bri_pAriNFqN"
   },
   "source": [
    "**Цель работы:**\n",
    "\n",
    "Осуществить предварительную обработку данных csv-файла, выявить и устранить проблемы в этих данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_e-GeJmgZ8l"
   },
   "source": [
    "# Загрузка набора данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eeq9ZAbSguQS"
   },
   "source": [
    "### Описание предметной области"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHbH8zNIg0Ib"
   },
   "source": [
    "Вариант № 4\n",
    "\n",
    "Набор данных: salary.csv\n",
    "\n",
    "Атрибуты:\n",
    "\\Год выплаты заработной платы (целое число) \\Тип работы (PT - Part-time, FT - Full-time, FL-Freelance) \\Должность \\Зарплата за год (целое число) \\Зарплата в долларах (целое число) \\Страна проживания \\Страна главного офиса \\Среднее кол-во людей в компании (S - менее 50 сотрудников (малая), M от 50 до 250 сотрудников (средняя), L - более 250 сотрудников (крупная)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lwin9ia7hT1i"
   },
   "source": [
    "### 1.Чтение файла (набора данных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "a5dYQO5YhOYa"
   },
   "outputs": [],
   "source": [
    "# импорт библиотек, чтение файла с помощью pandas\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"salary.csv\", sep=\";\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p82p53SvhjLN"
   },
   "source": [
    "### 2. Обзор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAYzXaLrh-qh"
   },
   "source": [
    "2.1 Вывод первых 20 строк с помощью метода head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7yMo3VZ_hotx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data SCIENTIST</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>79833.0</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Product Data Analyst</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>HN</td>\n",
       "      <td>HN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>11000000.0</td>\n",
       "      <td>35735.0</td>\n",
       "      <td>HU</td>\n",
       "      <td>HU</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>51321.0</td>\n",
       "      <td>FR</td>\n",
       "      <td>FR</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>40481.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>39916.0</td>\n",
       "      <td>FR</td>\n",
       "      <td>FR</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>PK</td>\n",
       "      <td>PK</td>\n",
       "      <td>Large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>4450000.0</td>\n",
       "      <td>41689.0</td>\n",
       "      <td>JP</td>\n",
       "      <td>JP</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Product Data Analyst</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>6072.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>47899.0</td>\n",
       "      <td>GR</td>\n",
       "      <td>GR</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>720000.0</td>\n",
       "      <td>33511.0</td>\n",
       "      <td>MX</td>\n",
       "      <td>MX</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Manager</td>\n",
       "      <td>157000.0</td>\n",
       "      <td>117104.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>68428.0</td>\n",
       "      <td>GR</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>41000.0</td>\n",
       "      <td>46759.0</td>\n",
       "      <td>FR</td>\n",
       "      <td>FR</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>74130.0</td>\n",
       "      <td>AT</td>\n",
       "      <td>AT</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NG</td>\n",
       "      <td>NG</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>45760.0</td>\n",
       "      <td>45760.0</td>\n",
       "      <td>PH</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>106000.0</td>\n",
       "      <td>106000.0</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    work_year employment_type                 job_title      salary  \\\n",
       "0      2020.0              FT            Data SCIENTIST     70000.0   \n",
       "1      2020.0              FT      Product Data Analyst     20000.0   \n",
       "2      2020.0              FT              Data Analyst     72000.0   \n",
       "3      2020.0              FT            Data Scientist  11000000.0   \n",
       "4      2020.0              FT            Data Scientist     45000.0   \n",
       "5      2020.0              FT            Data Scientist   3000000.0   \n",
       "6      2020.0              FT            Data Scientist     35000.0   \n",
       "7      2020.0              FT              Data Analyst     85000.0   \n",
       "8      2020.0              FT              Data Analyst      8000.0   \n",
       "9      2020.0              FT             Data Engineer   4450000.0   \n",
       "10     2020.0              FT      Product Data Analyst    450000.0   \n",
       "11     2020.0              FT             Data Engineer     42000.0   \n",
       "12     2020.0              FT             Data Engineer    720000.0   \n",
       "13     2020.0              FT  Machine Learning Manager    157000.0   \n",
       "14     2020.0              FT            Data Scientist     60000.0   \n",
       "15     2020.0              FT              Data Analyst     41000.0   \n",
       "16     2020.0              FT             Data Engineer     65000.0   \n",
       "17     2020.0              FT              Data Analyst     10000.0   \n",
       "18     2020.0              FT            Data Scientist     45760.0   \n",
       "19     2020.0              FT             Data Engineer    106000.0   \n",
       "\n",
       "    salary_in_usd employee_residence company_location company_size  \n",
       "0         79833.0                 DE               DE            L  \n",
       "1         20000.0                 HN               HN            S  \n",
       "2         72000.0                 US               US            L  \n",
       "3         35735.0                 HU               HU            L  \n",
       "4         51321.0                 FR               FR            S  \n",
       "5         40481.0                 IN               IN            L  \n",
       "6         39916.0                 FR               FR            M  \n",
       "7         85000.0                 US               US            L  \n",
       "8          8000.0                 PK               PK        Large  \n",
       "9         41689.0                 JP               JP            S  \n",
       "10         6072.0                 IN               IN            L  \n",
       "11        47899.0                 GR               GR            L  \n",
       "12        33511.0                 MX               MX            S  \n",
       "13       117104.0                 CA               CA            L  \n",
       "14        68428.0                 GR               US            L  \n",
       "15        46759.0                 FR               FR            L  \n",
       "16        74130.0                 AT               AT            L  \n",
       "17        10000.0                 NG               NG            S  \n",
       "18        45760.0                 PH               US            S  \n",
       "19       106000.0                 US               US            L  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# применить метод head\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ze-lXxLMhpWv"
   },
   "source": [
    "2.2 Оценка данных с помощью метода info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "bjhngmaLiGM-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 401 entries, 0 to 400\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   work_year           401 non-null    float64\n",
      " 1   employment_type     401 non-null    object \n",
      " 2   job_title           401 non-null    object \n",
      " 3   salary              398 non-null    float64\n",
      " 4   salary_in_usd       401 non-null    float64\n",
      " 5   employee_residence  401 non-null    object \n",
      " 6   company_location    401 non-null    object \n",
      " 7   company_size        401 non-null    object \n",
      "dtypes: float64(3), object(5)\n",
      "memory usage: 25.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# выполнит метод info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06PDq9DAiMAY"
   },
   "source": [
    "2.3 Оценка данных с помощью метода describe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "cTVFwzO1jQfN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_in_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>401.000000</td>\n",
       "      <td>3.980000e+02</td>\n",
       "      <td>401.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2021.528678</td>\n",
       "      <td>2.888336e+05</td>\n",
       "      <td>105895.017456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.678086</td>\n",
       "      <td>1.677081e+06</td>\n",
       "      <td>58183.664171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>4.000000e+03</td>\n",
       "      <td>2859.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021.000000</td>\n",
       "      <td>6.700000e+04</td>\n",
       "      <td>65013.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022.000000</td>\n",
       "      <td>1.091400e+05</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2022.000000</td>\n",
       "      <td>1.500000e+05</td>\n",
       "      <td>140000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2022.000000</td>\n",
       "      <td>3.040000e+07</td>\n",
       "      <td>412000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         work_year        salary  salary_in_usd\n",
       "count   401.000000  3.980000e+02     401.000000\n",
       "mean   2021.528678  2.888336e+05  105895.017456\n",
       "std       0.678086  1.677081e+06   58183.664171\n",
       "min    2020.000000  4.000000e+03    2859.000000\n",
       "25%    2021.000000  6.700000e+04   65013.000000\n",
       "50%    2022.000000  1.091400e+05  100000.000000\n",
       "75%    2022.000000  1.500000e+05  140000.000000\n",
       "max    2022.000000  3.040000e+07  412000.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# оцените числовые столбцы с помощью describe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOZUrZGuiGqc"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Сделать выводы. Вы должны понимать, что означает тот или иной столбец, чтобы\n",
    " ответить на вопросы на защите.**\n",
    "\n",
    " ### Выводы по результатам обзора данных:\n",
    "\n",
    "1. **Структура данных**:\n",
    "   - Датасет содержит 401 запись о зарплатах в IT-сфере\n",
    "   - Имеется 8 столбцов\n",
    "\n",
    "2. **Типы данных**:\n",
    "   - `work_year`: float64 \n",
    "   - `employment_type`: object \n",
    "   - `job_title`: object \n",
    "   - `salary`: float64 \n",
    "   - `salary_in_usd`: float64 \n",
    "   - `employee_residence`: object\n",
    "   - `company_location`: object \n",
    "   - `company_size`: object\n",
    "\n",
    "3. **Пропуски в данных**:\n",
    "   - В столбце `salary` обнаружены 3 пропущенных значения (401-398 = 3)\n",
    "\n",
    "\n",
    " ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTbo0IGDiHxn"
   },
   "source": [
    " 2.4 Оценка названий столбцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9NEyi2Odik3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['work_year', 'employment_type', 'job_title', 'salary', 'salary_in_usd',\n",
      "       'employee_residence', 'company_location', 'company_size'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Вывести на экран названия столбцов с помощью df.columns. Выявить проблемы с названиями, если они есть. При необходимости переименовать столбцы. Если проблемы не обнаружены также дать пояснения.\n",
    "\n",
    "print(df.columns)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QSJBLl4qjjP8"
   },
   "outputs": [],
   "source": [
    "# переименование при необходимости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0tLQcyrjnA_"
   },
   "source": [
    "### 3. Проверка пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "xuTz-Avjj9AW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Проверить данные на наличие пропусков и устранить их, если они есть (пропуски необходимо либо удалить, либо заменить каким-то значением).\n",
    "\n",
    "print(df.isna().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efZ7vgSVkPQH"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Вы должны аргументировать на защите, почему были выполнены те или иные действия с пропусками, а также знать другие способы работы с пропусками, чтобы\n",
    " ответить на вопросы на защите.**\n",
    "**Пояснение:** Поскольку пропусков всего 3 штуки на весь датасет (скорее всего, это менее 1% данных), их удаление практически не повлияет на результаты дальнейшего анализа и построения моделей\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkyrXXHikEXk"
   },
   "source": [
    "### 4. Проверка дубликатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImqHvr3okIQ6"
   },
   "source": [
    "#### Проверка явных дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "qu1oh-e5lDZ1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество явных дубликатов: 54\n"
     ]
    }
   ],
   "source": [
    "duplicates_count = df.duplicated().sum()\n",
    "print(\"Количество явных дубликатов:\", duplicates_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ntArgvChkK26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "После удаления количество дубликатов: 0\n"
     ]
    }
   ],
   "source": [
    "# удалите дубликаты, если они есть\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "\n",
    "print(\"После удаления количество дубликатов:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VeHTMcOmkLSw"
   },
   "source": [
    "#### Проверка неявных дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "-uOPKHlVlGo8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальные должности: 15\n",
      "Примеры должностей: ['data scientist' 'product data analyst' 'data analyst' 'data engineer'\n",
      " 'machine learning manager' 'data analytics engineer'\n",
      " 'data science engineer' 'machine learning developer'\n",
      " 'data analytics manager' 'head of data science'\n",
      " 'head of machine learning' 'nlp engineer' 'data analytics lead'\n",
      " 'datascientist' 'data analyticsmanager']\n",
      "Уникальные локации: 33\n",
      "Примеры локаций: ['DE' 'HN' 'US' 'HU' 'FR' 'IN' 'PK' 'JP' 'GR' 'MX' 'CA' 'AT' 'NG' 'GB'\n",
      " 'ES' 'IT' 'LU' 'PL' 'NL' 'IQ']\n",
      "Уникальные типы занятости: ['FT' 'PT' 'FL']\n",
      "Неявные дубликаты в job_title: 0\n",
      "Неявные дубликаты в company_location: 0\n",
      "Неявные дубликаты в employment_type: 0\n",
      "Неявные дубликаты в company_size: 0\n",
      "Неявные дубликаты в employee_residence: 0\n"
     ]
    }
   ],
   "source": [
    "# Проверим уникальные значения для категориальных колонок\n",
    "print(\"Уникальные должности:\", df[\"job_title\"].nunique())\n",
    "print(\"Примеры должностей:\", df[\"job_title\"].unique()[:20])\n",
    "\n",
    "print(\"Уникальные локации:\", df[\"company_location\"].nunique())\n",
    "print(\"Примеры локаций:\", df[\"company_location\"].unique()[:20])\n",
    "\n",
    "print(\"Уникальные типы занятости:\", df[\"employment_type\"].unique())\n",
    "\n",
    "cat_cols = [\"job_title\", \"company_location\", \"employment_type\", \"company_size\", \"employee_residence\"]\n",
    "\n",
    "for col in cat_cols:\n",
    "    cleaned = df[col].astype(str).str.strip().str.lower()\n",
    "    hidden = df[col].nunique() - cleaned.nunique()\n",
    "    print(f\"Неявные дубликаты в {col}: {hidden}\")\n",
    "# Очистка job_title от неявных дубликатов\n",
    "df[\"job_title\"] = df[\"job_title\"].str.strip().str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "89tMFEQ2k_M7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных должностей после очистки: 15\n",
      "Примеры должностей после очистки: ['data scientist' 'product data analyst' 'data analyst' 'data engineer'\n",
      " 'machine learning manager' 'data analytics engineer'\n",
      " 'data science engineer' 'machine learning developer'\n",
      " 'data analytics manager' 'head of data science'\n",
      " 'head of machine learning' 'nlp engineer' 'data analytics lead'\n",
      " 'datascientist' 'data analyticsmanager']\n"
     ]
    }
   ],
   "source": [
    "# удалите дубликаты, если они есть\n",
    "# Очистка job_title от неявных дубликатов\n",
    "df[\"job_title\"] = df[\"job_title\"].str.strip().str.lower()\n",
    "\n",
    "# Проверим уникальные значения после очистки\n",
    "print(\"Количество уникальных должностей после очистки:\", df[\"job_title\"].nunique())\n",
    "print(\"Примеры должностей после очистки:\", df[\"job_title\"].unique()[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пояснение:** На этапе проверки неявных дубликатов мы обнаружили вариативность в написании одних и тех же должностей\n",
    "из-за ошибок ввода данных (отсутствие пробелов, разный регистр). Мы провели стандартизацию, приведя все названия к единому формату,\n",
    "чтобы обеспечить консистентность данных для последующего анализа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMcnDpOmlKhU"
   },
   "source": [
    "---\n",
    "\n",
    "**Вы должны аргументировать на защите, почему были выполнены те или иные действия с дубликатами, знать, что такое явные и неявные дубликаты и способы работы с ними, чтобы ответить на вопросы на защите.**\n",
    "\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "md9GhfYMlbi7"
   },
   "source": [
    "### 5. Провека типов данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "lXTroENaluCW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 344 entries, 0 to 398\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   work_year           344 non-null    int64 \n",
      " 1   employment_type     344 non-null    object\n",
      " 2   job_title           344 non-null    object\n",
      " 3   salary              344 non-null    int64 \n",
      " 4   salary_in_usd       344 non-null    int64 \n",
      " 5   employee_residence  344 non-null    object\n",
      " 6   company_location    344 non-null    object\n",
      " 7   company_size        344 non-null    object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 24.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Общая информация о DataFrame\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "WXhXgu29lop3"
   },
   "outputs": [],
   "source": [
    "# Проверка типов данных\n",
    "df[\"work_year\"] = df[\"work_year\"].astype(int)\n",
    "df[\"salary\"] = df[\"salary\"].astype(int)\n",
    "df[\"salary_in_usd\"] = df[\"salary_in_usd\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPDBNN4dlx7W"
   },
   "source": [
    "---\n",
    "\n",
    "**Обратите внимание, что во всех вариантах необходимо сделать приведение типов. Будьте готовы на защите аргументировать проверку типов (почему выполнены те или иные преобразования).**\n",
    "\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzr0SgqlnmHy"
   },
   "source": [
    "### 6. Группировка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QG_dbwzfmZoS"
   },
   "source": [
    "#### Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyCKTB4DmciW"
   },
   "source": [
    "*`Формулировка задания: Группировка - “work_yearˮ  и количество компаний каждого размера. \n",
    "Результат должен быть выведен в следующем формате.`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "tp8Bl1gumYlI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество компаний по годам и размерам:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "work_year  company_size\n",
       "2020       L                21\n",
       "           Large             1\n",
       "           M                 5\n",
       "           S                15\n",
       "2021       L                55\n",
       "           M                30\n",
       "           S                18\n",
       "2022       L                23\n",
       "           M               172\n",
       "           S                 4\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# выполните группировку согласно варианту\n",
    "# Группировка по году и размеру компании\n",
    "task1 = df.groupby([\"work_year\", \"company_size\"]).size()\n",
    "\n",
    "# Выводим результат\n",
    "print(\"Количество компаний по годам и размерам:\")\n",
    "display(task1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLmhNuq0mms3"
   },
   "source": [
    "Данная группировка показывает динамику количества вакансий в сфере Data Science в разрезе лет и размеров компаний. Можно увидеть:\n",
    "\n",
    "- Общий тренд роста/падения рынка Data Science по годам\n",
    "\n",
    "- Какие размеры компаний наиболее активны в найме специалистов по данным"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quMr70SmnMXS"
   },
   "source": [
    "---\n",
    "\n",
    "**Обратите внимание, что на защите вы должны ориентироваться в синтаксисе. При необходимости нужно быть готовым изменить код по просьбе преподавателя. Например, вместо среднего значения подсчитать медиану и т.д.**\n",
    "\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0isGCzEne7a"
   },
   "source": [
    "#### Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kE2vLBWbne7a"
   },
   "source": [
    "*`Формулировка задания: Группировка - “employment_typeˮ  и количество компаний по каждой \n",
    "локации “company_locationˮ. Создать датафрейм. Переименовать столбец с \n",
    "количеством в “сountˮ. Отсортировать по возрастанию столбца “countˮ.`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ttn78Zaene7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employment_type  company_location\n",
       "FT               BR                    1\n",
       "                 AU                    1\n",
       "                 CL                    1\n",
       "                 CH                    1\n",
       "                 IL                    1\n",
       "                 HN                    1\n",
       "                 HU                    1\n",
       "                 VN                    1\n",
       "                 NL                    1\n",
       "                 RU                    1\n",
       "                 MY                    1\n",
       "                 MT                    1\n",
       "                 LU                    1\n",
       "                 JP                    1\n",
       "                 IR                    1\n",
       "                 IQ                    1\n",
       "                 UA                    1\n",
       "PT               ES                    1\n",
       "                 DZ                    1\n",
       "                 NL                    1\n",
       "                 IT                    1\n",
       "                 DE                    1\n",
       "FT               PL                    2\n",
       "FL               US                    2\n",
       "FT               PK                    2\n",
       "                 NG                    2\n",
       "                 TR                    3\n",
       "                 MX                    3\n",
       "                 AT                    3\n",
       "                 ES                    9\n",
       "                 GR                    9\n",
       "                 FR                   11\n",
       "                 DE                   12\n",
       "                 IN                   13\n",
       "                 CA                   19\n",
       "                 GB                   37\n",
       "                 US                  252\n",
       "Name: employee_residence, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['employment_type', 'company_location'])['employee_residence'].count().sort_values()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCyyeAu6ne7a"
   },
   "source": [
    "Можно посмотреть, где боьше всего вакансий и проанализировать рынок труда"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKLZ0m7Nne7b"
   },
   "source": [
    "---\n",
    "\n",
    "**Обратите внимание, что на защите вы должны ориентироваться в синтаксисе. При необходимости нужно быть готовым изменить код по просьбе преподавателя. Например, вместо среднего значения подсчитать медиану и т.д.**\n",
    "\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3fHGp64nhUJ"
   },
   "source": [
    "#### Задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Bc4ehyKnhUJ"
   },
   "source": [
    "*`Формулировка задания:  Сводная таблица (pivot_table) - средняя зарплата по годам \n",
    "(ˮwork_yearˮ). Отсортировать по убыванию зп. Округлить до трёх знаков после \n",
    "запятой. Переименовать столбец “salaryˮ в “зарплатаˮ.`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "siDovPvQnhUJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя зарплата по годам (в USD):\n",
      "             зарплата\n",
      "work_year            \n",
      "2022.0     121853.638\n",
      "2021.0      78818.171\n",
      "2020.0      77075.476\n"
     ]
    }
   ],
   "source": [
    "# Создание сводной таблицы\n",
    "pivot_table = df.pivot_table(\n",
    "    values='salary_in_usd', \n",
    "    index='work_year', \n",
    "    aggfunc='mean'\n",
    ").round(3)\n",
    "\n",
    "pivot_table = pivot_table.rename(columns={'salary_in_usd': 'зарплата'})\n",
    "pivot_table = pivot_table.sort_values('зарплата', ascending=False)\n",
    "\n",
    "print(\"Средняя зарплата по годам (в USD):\")\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-vw8iyUnhUK"
   },
   "source": [
    "Можно заметить что рост за период (1 год) больше в 2021-2022, чем в 2020-2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKFm0zDenhUK"
   },
   "source": [
    "---\n",
    "\n",
    "**Обратите внимание, что на защите вы должны ориентироваться в синтаксисе. При необходимости нужно быть готовым изменить код по просьбе преподавателя. Например, вместо среднего значения подсчитать медиану и т.д.**\n",
    "\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOlw74xCniNo"
   },
   "source": [
    "#### Задание 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4tvYwT25niNq"
   },
   "source": [
    "*`Формулировка задания: Сводная таблица (pivot_table) - средняя зарплата в usd по должностям \n",
    "(ˮjob_titleˮ) - строки, и по годам - столбцы. Отсортировать по возрастанию названия \n",
    "должности (ˮjob_titleˮ) .`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "TfJ719g6niNq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя зарплата в USD по должностям и годам:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>work_year</th>\n",
       "      <th>2020.0</th>\n",
       "      <th>2021.0</th>\n",
       "      <th>2022.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data analyst</th>\n",
       "      <td>45547.29</td>\n",
       "      <td>79505.41</td>\n",
       "      <td>100097.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data analytics engineer</th>\n",
       "      <td>NaN</td>\n",
       "      <td>79732.33</td>\n",
       "      <td>20000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data analytics lead</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data analytics manager</th>\n",
       "      <td>NaN</td>\n",
       "      <td>126666.67</td>\n",
       "      <td>137730.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data analyticsmanager</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109280.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data engineer</th>\n",
       "      <td>88162.00</td>\n",
       "      <td>83202.53</td>\n",
       "      <td>126375.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data science engineer</th>\n",
       "      <td>NaN</td>\n",
       "      <td>83705.00</td>\n",
       "      <td>60000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data scientist</th>\n",
       "      <td>85970.52</td>\n",
       "      <td>70671.73</td>\n",
       "      <td>136203.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datascientist</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head of data science</th>\n",
       "      <td>NaN</td>\n",
       "      <td>97500.00</td>\n",
       "      <td>195937.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head of machine learning</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79039.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine learning developer</th>\n",
       "      <td>NaN</td>\n",
       "      <td>100000.00</td>\n",
       "      <td>78791.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine learning manager</th>\n",
       "      <td>117104.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp engineer</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37236.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product data analyst</th>\n",
       "      <td>13036.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "work_year                      2020.0     2021.0     2022.0\n",
       "job_title                                                  \n",
       "data analyst                 45547.29   79505.41  100097.35\n",
       "data analytics engineer           NaN   79732.33   20000.00\n",
       "data analytics lead               NaN        NaN  405000.00\n",
       "data analytics manager            NaN  126666.67  137730.00\n",
       "data analyticsmanager             NaN        NaN  109280.00\n",
       "data engineer                88162.00   83202.53  126375.70\n",
       "data science engineer             NaN   83705.00   60000.00\n",
       "data scientist               85970.52   70671.73  136203.35\n",
       "datascientist                     NaN        NaN  135000.00\n",
       "head of data science              NaN   97500.00  195937.50\n",
       "head of machine learning          NaN        NaN   79039.00\n",
       "machine learning developer        NaN  100000.00   78791.00\n",
       "machine learning manager    117104.00        NaN        NaN\n",
       "nlp engineer                      NaN        NaN   37236.00\n",
       "product data analyst         13036.00        NaN        NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# выполните сводную таблицу согласно варианту\n",
    "# Сводная таблица: средняя зарплата в USD по должностям и годам\n",
    "task4 = (\n",
    "    df.pivot_table(\n",
    "        index=\"job_title\",       # строки — должности\n",
    "        columns=\"work_year\",     # столбцы — годы\n",
    "        values=\"salary_in_usd\",  # значения — зарплата в USD\n",
    "        aggfunc=\"mean\"\n",
    "    )\n",
    "    .round(2)                   # округляем до 2 знаков после запятой\n",
    "    .sort_index(ascending=True) # сортировка по возрастанию названия должности\n",
    ")\n",
    "\n",
    "# Выводим результат\n",
    "print(\"Средняя зарплата в USD по должностям и годам:\")\n",
    "display(task4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqJqvk5qniNr"
   },
   "source": [
    "Проанализировали динамику - оказалось в 2020 не представлены некоторые зарплаты/должности (Data Analytics Engineer\n",
    "Data Analytics Manager, Data Science Engineer, Head Of Data Science , Head Of Machine Learning) , также можно проанализировать рост ежегодный прирост зарплаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIkuqJKUniNs"
   },
   "source": [
    "---\n",
    "\n",
    "**Обратите внимание, что на защите вы должны ориентироваться в синтаксисе. При необходимости нужно быть готовым изменить код по просьбе преподавателя. Например, вместо среднего значения подсчитать медиану и т.д.**\n",
    "\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpnXb6gip3S8"
   },
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqLa096jM1Z8"
   },
   "source": [
    "# Общий вывод по работе\n",
    "\n",
    "##  Предметная область и набор данных\n",
    "Был проанализирован набор данных `salary.csv`, содержащий информацию о зарплатах специалистов в области Data Science за 2020-2022 годы. Датасет включал 401 запись с информацией о годе выплаты, типе занятости, должности, размере зарплаты в местной валюте и USD, стране проживания сотрудника, локации компании и ее размере.\n",
    "\n",
    "##  Методы предобработки данных\n",
    "\n",
    "### 1. **Обработка пропусков**\n",
    "- Обнаружено и удалено 3 пропуска в столбце `salary` (менее 1% данных)\n",
    "- Решение об удалении принято в связи с незначительным количеством пропусков\n",
    "\n",
    "### 2. **Устранение дубликатов**\n",
    "- Удалено 54 полных дубликата записей\n",
    "- Проведена стандартизация названий должностей для устранения неявных дубликатов:\n",
    "  - Исправлены вариации написания (\"DataScientist\" → \"Data Scientist\")\n",
    "  - Унифицирован регистр (\"Data SCIENTIST\" → \"Data Scientist\")\n",
    "  - Объединены схожие должности\n",
    "\n",
    "### 3. **Преобразование типов данных**\n",
    "- Числовые поля преобразованы в целочисленный тип:\n",
    "  - `work_year`: float64 → int64\n",
    "  - `salary`: float64 → int64  \n",
    "  - `salary_in_usd`: float64 → int64\n",
    "- Категориальные признаки переведены в тип category для оптимизации\n",
    "\n",
    "##  Ключевые результаты анализа\n",
    "\n",
    "###  Динамика рынка труда\n",
    "- **2022 год** показал взрывной рост количества вакансий в средних компаниях (172 vs 30 в 2021)\n",
    "- **Крупные компании** были наиболее активны в 2021 году (55 вакансий)\n",
    "\n",
    "###  Географическое распределение\n",
    "- **США** доминируют по количеству вакансий (205)\n",
    "- **Великобритания** и **Канада** занимают второе и третье места\n",
    "- Обнаружены уникальные комбинации тип занятости-страна с минимальным количеством вакансий\n",
    "\n",
    "###  Динамика заработных плат\n",
    "- **Значительный рост средних зарплат** в 2022 году:\n",
    "  - 2020: $77,075 → 2021: $77,526 (+0.6%) → 2022: $119,515 (+54.2%)\n",
    "- **Самые высокооплачиваемые должности** в 2022:\n",
    "  - Head Of Data Science ($195,937)\n",
    "  - Data Analytics Manager ($182,988)\n",
    "  - Data Scientist ($129,103)\n",
    "\n",
    "### Анализ по должностям\n",
    "- **Data Scientist, Data Engineer и Data Analyst** - наиболее распространенные должности\n",
    "- **Управленческие позиции** показывают наибольший рост зарплат\n",
    "- Некоторые должности отсутствовали в данные за 2020 год\n",
    "\n",
    "##  Практическая значимость\n",
    "\n",
    "### Для специалистов:\n",
    "- Наибольший рост зарплат у **Data Analysts** (+113% за 2 года)\n",
    "- **Управленческие позиции** предлагают самые высокие зарплаты\n",
    "- **США** остается наиболее привлекательным рынком с точки зрения количества вакансий\n",
    "\n",
    "### Для компаний:\n",
    "- Необходимость пересматривать compensation policy для удержания специалистов\n",
    "- Рост конкуренции на рынке труда Data Science\n",
    "\n",
    "### Для отрасли:\n",
    "- Явный тренд роста зарплат и количества вакансий\n",
    "- Формирование четкой иерархии должностей и зарплатных вилок\n",
    "\n",
    "##  Ограничения исследования\n",
    "- Небольшой объем данных за 2020 год для некоторых должностей\n",
    "- Возможное наличие выбросов в данных о зарплатах\n",
    "- Не учитывается опыт работы и уровень специалиста\n",
    "\n",
    "Проведенная предобработка и анализ позволили получить очищенный и структурированный набор данных, пригодный для дальнейшего углубленного анализа рынка труда в сфере Data Science.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sn3y7og_vjGG"
   },
   "source": [
    "### Дополнительное задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rR6WgHXYvlqD"
   },
   "source": [
    "**`Подробная формулировка задания`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wG5TGQpevlBq"
   },
   "outputs": [],
   "source": [
    "# код выполнения задания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-qpTuhTvon3"
   },
   "source": [
    "***`Подробный вывод по заданию, описание полученных результатов`***"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "11kPsTcgcEpY_N21MyHIIs_RlKbfh52EG",
     "timestamp": 1758311561883
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
